{
  "prompts": [
    {
      "prompt_data": {
        "context": "Act as Yoda from Star Wars.",
        "messages": [
          {
            "role": "user",
            "content": "Hello, how are you?"
          }
        ]
      },
      "model_parameters": {
        "max_tokens": 700,
        "temperature": "0.26",
        "top_p": "0"
      },
      "description": "A chat prompt to act as Yoda from Star Wars.",
      "name": "yoda-test",
      "prompt_variables": {}
    },
    {
      "name": "short-story",
      "description": "A short story generation prompt using variables.",
      "prompt_data": {
        "prompt": "Generate a 2 sentence short story with the following information:\n\nSetting: {{setting}}\nPlot: {{plot}}\nCharacter: {{character}}"
      },
      "prompt_variables": {
        "setting": {
          "type": "text",
          "value": "an old stone home"
        },
        "plot": {
          "type": "text",
          "value": "knock on door"
        },
        "character": {
          "type": "text",
          "value": "an old farmer and his wife"
        }
      }
    }
  ],
  "models": [
    {
      "name": "gpt-3.5-turbo (OpenAI)",
      "type": "chat",
      "model_parameters": {
        "roles": ["user", "assistant"],
        "max_tokens": {
          "key": "max_tokens",
          "type": "slider",
          "name": "Max Tokens",
          "default": 2000,
          "step": 50,
          "min": 0,
          "max": 4000
        },
        "temperature": {
          "key": "temperature",
          "type": "slider",
          "name": "Temperature",
          "default": 0.7,
          "step": 0.01,
          "min": 0,
          "max": 1
        },
        "top_p": {
          "key": "top_p",
          "type": "slider",
          "name": "Top P",
          "default": 1,
          "step": 0.01,
          "min": 0,
          "max": 1
        },
        "stop_sequence": {
          "key": "stop_sequence",
          "type": "tags",
          "name": "Stop Sequence",
          "default": []
        }
      },
      "api_call": {
        "url": "https://api.openai.com/v1/chat/completions",
        "method": "POST",
        "headers": {
          "Authorization": "Bearer {{OPEN_AI_KEY}}",
          "Content-Type": "application/json"
        },
        "data": {}
      },
      "input_format": "(function(prompt_data, model_parameters) { const formattedParameters = {}; for (const key in model_parameters) { const value = model_parameters[key]; const parsedValue = parseFloat(value); if (!isNaN(parsedValue)) { if (Number.isInteger(parsedValue)) { formattedParameters[key] = parseInt(parsedValue); } else { formattedParameters[key] = parsedValue; } } else { formattedParameters[key] = value; } } const output = { model: 'gpt-3.5-turbo', messages: [ ...(prompt_data.context ? [{ role: 'system', content: prompt_data.context }] : []), ...(prompt_data.messages.filter(message => message.role !== 'system')) ], ...formattedParameters }; return output; })",
      "output_format": "(function(data) { if (data && data.choices && data.choices.length > 0) { var message = data.choices[0].message; return message} return ''; })",
      "default": true
    },
    {
      "name": "gpt-3.5-turbo completion (OpenAI)",
      "type": "completion",
      "model_parameters": {
        "roles": ["user", "assistant"],
        "max_tokens": {
          "key": "max_tokens",
          "type": "slider",
          "name": "Max Tokens",
          "default": 2000,
          "step": 50,
          "min": 0,
          "max": 4000
        },
        "temperature": {
          "key": "temperature",
          "type": "slider",
          "name": "Temperature",
          "default": 0.7,
          "step": 0.01,
          "min": 0,
          "max": 1
        },
        "top_p": {
          "key": "top_p",
          "type": "slider",
          "name": "Top P",
          "default": 1,
          "step": 0.01,
          "min": 0,
          "max": 1
        },
        "stop_sequence": {
          "key": "stop_sequence",
          "type": "tags",
          "name": "Stop Sequence",
          "default": []
        }
      },
      "api_call": {
        "url": "https://api.openai.com/v1/chat/completions",
        "method": "POST",
        "headers": {
          "Authorization": "Bearer {{OPEN_AI_KEY}}",
          "Content-Type": "application/json"
        },
        "data": {}
      },
      "input_format": "(function(prompt_data, model_parameters) { const formattedParameters = {}; for (const key in model_parameters) { const value = model_parameters[key]; const parsedValue = parseFloat(value); if (!isNaN(parsedValue)) { if (Number.isInteger(parsedValue)) { formattedParameters[key] = parseInt(parsedValue); } else { formattedParameters[key] = parsedValue; } } else { formattedParameters[key] = value; } } const output = { model: 'gpt-3.5-turbo', messages: [{ role: 'system', content: prompt_data.prompt }], ...formattedParameters }; return output; })",
      "output_format": "(function(data) { if (data && data.choices && data.choices.length > 0) { var message = data.choices[0].message['content']; return message} return ''; })",
      "default": true
    }
  ]
}
